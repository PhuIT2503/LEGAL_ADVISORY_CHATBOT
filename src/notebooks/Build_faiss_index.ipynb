{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wxktK225aucZ",
        "outputId": "a2cf7eae-f1fa-4aa8-d260-3b2e3078efcc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n",
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.12/dist-packages (1.12.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: sqlalchemy in /usr/local/lib/python3.12/dist-packages (2.0.43)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from transformers) (3.19.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.35.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (25.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from transformers) (2.32.4)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy) (3.2.4)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->transformers) (2025.8.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers torch faiss-cpu tqdm sqlalchemy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469,
          "referenced_widgets": [
            "c413db5042874938b187ee6b9a919a46",
            "52a4c86437ba41e68186337f9543cbdb",
            "f8bf5c0eeb7641d78b29f28c0adb8bd9",
            "bd34a65e00914ade9af51d82616a030e",
            "554b07d8d7a141879c2540cbc3c1bc72",
            "c37521afc10a4927a62cf900cb775d8d",
            "9db23a0b5670488cb4174468cadf09eb",
            "ac9e89b5da504608a06db5a418fc9300",
            "85309cb2eaf94f299b127c44b96c8d3d",
            "cf117522c0aa496c907487d895ffbca7",
            "6ff23f021eab41b28aac658841bff627",
            "71dc4957f7114b0a83c217ebd6da4f42",
            "713bb853b520486689e8fb44e73708f3",
            "2fdf03ca70ad4a94b3956947a69f2ed4",
            "b70c86885aa8403fb515f4d2d49165c0",
            "10d31165b461433298e8f9d070558a7a",
            "b202dd3f884b47ab907f364865978596",
            "591c045fbd6f43f08b1dbc01db425862",
            "06bc68de65bc42a4beab788a717c20ca",
            "468f9b07410f4f8eb99d819301620000",
            "2962a1ca1c7e42adb3732d2f41a04ff6",
            "4ccb8831bc9a4531abbd30fcdd47cb93",
            "a834538202ab4431ad44517621162509",
            "5ac3027a462d44abbba7fa23ce07d4f7",
            "a5ea900114e9457592cc949266aa7da3",
            "933b3aa48c994ca1a0d5422c818664cd",
            "86cb1455cb3e42a893c7d926243a6472",
            "5a1dbf4eb0c6425fa6b4f994a3ab775a",
            "389273385e844b7d95fc655231f24e2f",
            "8a32eb4d4b1f4b7f86baecb66715b06c",
            "c96d4ed9d1074338ba18f73d10dba97e",
            "044183311b794528b7997213a454da9a",
            "25fbb1661fcd4cbd88186e3ae67f2c93",
            "84d27c722fb0499da5b2d0cb90cd9e68",
            "4c1891f2d9cb40dfa3274c4b2711e950",
            "ef4f5c0d37c04b798641f246ca14e92e",
            "aaf6d26627e84f0e8e81917d1277d155",
            "331474b3d942474e9e3d6102e70b207d",
            "db3f9f41389d4eb4b2be6f077e6592fd",
            "8f1b4884f09f43168f0ab71be1fe8f9a",
            "f4fd7f6b14a547efa9aa46fe43247baa",
            "e2c09b59a0194bb8a56078073800659e",
            "15065fe8e6be4951ab78dde14c5f173f",
            "4397527d1cbf47cbbd34b9de3e01018d",
            "9c5d8fa709bb4f8eba4fbfe6fbeefa6b",
            "9759b52c310b4d8890334a1637bb7e40",
            "49ddab834f084b5bbb7ea2b514ad94ee",
            "2636a9f4728546f190ca9d8fabbb5207",
            "0f2dffe4a97c44a6915a3ad664330ae0",
            "77da0147b19d4958bb4fb77a5c15e68e",
            "56f3d4750e874a4482f3625850a26f8d",
            "f26a0b5e5d524646ac572e4bfc30b2ea",
            "a51b5307dfd84255aadd9d1ac4afd005",
            "4f408d3d995c4f1e9fc7dea4feba946e",
            "4411440685034a75ae89b1556c98d375",
            "626b3cab7f9947758fa25c4818363f56",
            "45340b2a90564605b246d97b80f33de7",
            "fa77076b42334c48960c76d7875a0116",
            "de27f425e8de467fa16994034e022095",
            "8edc8cd7ebb34478ba51d04e4cf43ed3",
            "3d26fc30e1624267830edd411c0dafa9",
            "643704b737824a46899bb1cf167c3653",
            "049c9c77c9324003b11401d627458ddf",
            "52141d7051944fe7964f1f7d29d7ec16",
            "7937c64f5e1d4ae2b24194d6f2f4452e",
            "df29ff998c3544e98f633250db69fdb1",
            "c57147240f054dc4a3fe64f2e2dfb6df",
            "7a4aff5318044ce28b7c23e494ee8cfb",
            "90e3f733972f47b5a736b3e3316045b9",
            "14934f4f880b4e578771dc8b44afa8d8",
            "ad12c444a72342da9391ddbad546cab5",
            "57259c7d4995486991e91643e4069e33",
            "8caa5d6670584fd699526016ab735881",
            "04d8fa4d23fb4feb93e0ba089dd80a01",
            "7ebaa82f70964400907aa91431dbd4f1",
            "6a6045890a65417a9bad387fe7c47180",
            "224b5a1d3f334778873107cc8e5dde05"
          ]
        },
        "id": "ukZoPvOVaw2k",
        "outputId": "dfcb92f7-d85f-4ce4-a0f1-a5b3c85bf6f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c413db5042874938b187ee6b9a919a46",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/444 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "71dc4957f7114b0a83c217ebd6da4f42",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a834538202ab4431ad44517621162509",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "84d27c722fb0499da5b2d0cb90cd9e68",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/964 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9c5d8fa709bb4f8eba4fbfe6fbeefa6b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/687 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "626b3cab7f9947758fa25c4818363f56",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c57147240f054dc4a3fe64f2e2dfb6df",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/2.27G [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Docs built: 324920\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Embedding: 100%|██████████| 20308/20308 [3:11:47<00:00,  1.76it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Embeddings done: (324920, 1024)\n",
            "FAISS index saved to /content/drive/MyDrive/NCKH/PhapLuat_RAG/luu_tru_2/laws_bge.index\n",
            "Vector DB saved to /content/drive/MyDrive/NCKH/PhapLuat_RAG/luu_tru_2/laws_bge.db\n"
          ]
        }
      ],
      "source": [
        "import sqlite3, json\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import faiss\n",
        "\n",
        "BGE_MODEL = \"models/bge-m3-law\"\n",
        "MAX_LENGTH = 512\n",
        "BATCH_SIZE_GPU = 16\n",
        "BATCH_SIZE_CPU = 32\n",
        "\n",
        "FAISS_OUT = \"/content/drive/MyDrive/NCKH/PhapLuat_RAG/luu_tru_2/laws_bge.index\"\n",
        "VECTOR_DB = \"/content/drive/MyDrive/NCKH/PhapLuat_RAG/luu_tru_2/laws_bge.db\"\n",
        "DB_PATH = \"/content/drive/MyDrive/NCKH/PhapLuat_RAG/luu_tru_2/vbplfull.db\"\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(BGE_MODEL)\n",
        "model = AutoModel.from_pretrained(BGE_MODEL).to(device).eval()\n",
        "\n",
        "@torch.no_grad()\n",
        "def embed_texts(texts):\n",
        "    texts = [t if t and str(t).strip() else \"[PAD]\" for t in texts]\n",
        "    batch_size = BATCH_SIZE_GPU if device.type==\"cuda\" else BATCH_SIZE_CPU\n",
        "    embeddings_parts = []\n",
        "\n",
        "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Embedding\"):\n",
        "        batch = texts[i:i+batch_size]\n",
        "        enc = tokenizer(batch, padding=True, truncation=True, max_length=MAX_LENGTH, return_tensors=\"pt\")\n",
        "        enc = {k: v.to(device) for k,v in enc.items()}\n",
        "        out = model(**enc)\n",
        "        last_hidden = out.last_hidden_state\n",
        "        mask = enc[\"attention_mask\"].unsqueeze(-1).expand(last_hidden.size()).float()\n",
        "        summed = torch.sum(last_hidden * mask, dim=1)\n",
        "        counts = torch.clamp(mask.sum(dim=1), min=1e-9)\n",
        "        mean_pooled = summed / counts\n",
        "        arr = mean_pooled.cpu().numpy()\n",
        "        arr = arr / (np.linalg.norm(arr, axis=1, keepdims=True) + 1e-9)\n",
        "        embeddings_parts.append(arr.astype(\"float32\"))\n",
        "\n",
        "    return np.vstack(embeddings_parts)\n",
        "\n",
        "def build_docs_from_db(conn):\n",
        "    docs = []\n",
        "    sql = \"\"\"\n",
        "    SELECT\n",
        "        v.vanban_id, v.ten as ten_vb, v.so_hieu, v.ngay_ban_hanh, v.ngay_hieu_luc, v.co_quan,\n",
        "        c.chuong_id, c.ten as ten_chuong,\n",
        "        d.dieu_id, d.so as so_dieu, d.noi_dung as nd_dieu,\n",
        "        k.khoan_id, k.so as so_khoan, k.noi_dung as nd_khoan,\n",
        "        di.diem_id, di.so as so_diem, di.noi_dung as nd_diem\n",
        "    FROM vanban v\n",
        "    LEFT JOIN chuong c ON c.vanban_id = v.vanban_id\n",
        "    LEFT JOIN dieu d ON d.chuong_id = c.chuong_id\n",
        "    LEFT JOIN khoan k ON d.dieu_id = k.dieu_id\n",
        "    LEFT JOIN diem di ON k.khoan_id = di.khoan_id\n",
        "    ORDER BY v.vanban_id, c.chuong_id, d.dieu_id, k.khoan_id, di.diem_id;\n",
        "    \"\"\"\n",
        "    rows = conn.execute(sql).fetchall()\n",
        "\n",
        "    for r in rows:\n",
        "        (vanban_id, ten_vb, so_hieu, ngay_bh, ngay_hl, co_quan,\n",
        "         chuong_id, ten_chuong,\n",
        "         dieu_id, so_dieu, nd_dieu,\n",
        "         khoan_id, so_khoan, nd_khoan,\n",
        "         diem_id, so_diem, nd_diem) = r\n",
        "\n",
        "        # Nối nhãn theo thứ tự Điều, Khoản, Điểm\n",
        "        labels = []\n",
        "        if dieu_id:\n",
        "            labels.append(f\"Điều {so_dieu}\")\n",
        "        if khoan_id:\n",
        "            labels.append(f\"Khoản {so_khoan}\")\n",
        "        if diem_id:\n",
        "            labels.append(f\"Điểm {so_diem}\")\n",
        "\n",
        "        law_info = f\"Văn bản {ten_vb} ({so_hieu})\"\n",
        "\n",
        "        # Chọn content ưu tiên Điểm > Khoản > Điều\n",
        "        content = None\n",
        "        if diem_id and nd_diem:\n",
        "            content = nd_diem\n",
        "        elif khoan_id and nd_khoan:\n",
        "            content = nd_khoan\n",
        "        elif dieu_id and nd_dieu:\n",
        "            content = nd_dieu\n",
        "        else:\n",
        "            continue  # không có nội dung thì bỏ\n",
        "\n",
        "        # text nối đầy đủ\n",
        "        text = f\"[{law_info} - {', '.join(labels)}] {content}\"\n",
        "\n",
        "        # uuid đầy đủ\n",
        "        uuid_parts = [f\"vanban:{vanban_id}\", f\"chuong:{chuong_id}\"]\n",
        "        if dieu_id:\n",
        "            uuid_parts.append(f\"dieu:{dieu_id}\")\n",
        "        if khoan_id:\n",
        "            uuid_parts.append(f\"khoan:{khoan_id}\")\n",
        "        if diem_id:\n",
        "            uuid_parts.append(f\"diem:{diem_id}\")\n",
        "        uuid = \":\".join(uuid_parts)\n",
        "\n",
        "        metadata = {\n",
        "            \"vanban_id\": vanban_id, \"ten_vanban\": ten_vb, \"so_hieu\": so_hieu,\n",
        "            \"ngay_ban_hanh\": ngay_bh, \"ngay_hieu_luc\": ngay_hl, \"co_quan\": co_quan,\n",
        "            \"chuong_id\": chuong_id, \"ten_chuong\": ten_chuong,\n",
        "            \"dieu_id\": dieu_id, \"so_dieu\": so_dieu,\n",
        "            \"khoan_id\": khoan_id, \"so_khoan\": so_khoan,\n",
        "            \"diem_id\": diem_id, \"so_diem\": so_diem\n",
        "        }\n",
        "\n",
        "        docs.append({\"uuid\": uuid, \"text\": text, \"metadata\": metadata})\n",
        "\n",
        "    return docs\n",
        "\n",
        "def main():\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    docs = build_docs_from_db(conn)\n",
        "    print(\"Docs built:\", len(docs))\n",
        "\n",
        "    texts = [d[\"text\"] for d in docs]\n",
        "    embs = embed_texts(texts)\n",
        "    print(\"Embeddings done:\", embs.shape)\n",
        "\n",
        "    # FAISS index\n",
        "    dim = embs.shape[1]\n",
        "    index = faiss.IndexFlatIP(dim)\n",
        "    index.add(embs)\n",
        "    faiss.write_index(index, FAISS_OUT)\n",
        "    print(\"FAISS index saved to\", FAISS_OUT)\n",
        "\n",
        "    # Vector DB\n",
        "    conn_vec = sqlite3.connect(VECTOR_DB)\n",
        "    conn_vec.execute(\"\"\"\n",
        "    CREATE TABLE IF NOT EXISTS vectors (\n",
        "        uuid TEXT PRIMARY KEY,\n",
        "        faiss_id INTEGER,\n",
        "        doc_text TEXT,\n",
        "        metadata_json TEXT,\n",
        "        embedding BLOB,\n",
        "        created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "    );\"\"\")\n",
        "    conn_vec.commit()\n",
        "\n",
        "    for i, d in enumerate(docs):\n",
        "        conn_vec.execute(\"\"\"\n",
        "            INSERT OR REPLACE INTO vectors (uuid, faiss_id, doc_text, metadata_json, embedding)\n",
        "            VALUES (?, ?, ?, ?, ?)\n",
        "        \"\"\", (d[\"uuid\"], i, d[\"text\"], json.dumps(d[\"metadata\"], ensure_ascii=False), embs[i].tobytes()))\n",
        "\n",
        "    conn_vec.commit()\n",
        "    conn_vec.close()\n",
        "    conn.close()\n",
        "    print(\"Vector DB saved to\", VECTOR_DB)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
